{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3m9JjeM5U5"
   },
   "source": [
    "# **Programming Assessment \\#4**\n",
    "\n",
    "Names: Enriquez, Manolo L.  Narvaez, Jose Wilfredo S.\n",
    "\n",
    "More information on the assessment is found in our Canvas course. Link: https://dlsu.instructure.com/courses/93383/assignments/739602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxtmCAZwNoeU"
   },
   "source": [
    "# **Load Data**\n",
    "\n",
    "*While you don't have to separate your code into blocks, it might be easier if you separated loading your data from actually implementation of your code. Consider placing all loading of data into the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CbvxU2oTM4IV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\jolon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# Language Model\n",
    "all_words = Counter()\n",
    "for filename in nltk.corpus.gutenberg.fileids():\n",
    "  words = [word.lower() for word in nltk.corpus.gutenberg.words(filename)]\n",
    "  all_words.update(words)\n",
    "\n",
    "total_tokens = sum(all_words.values())\n",
    "total_words = len(all_words)\n",
    "\n",
    "# Error Model class\n",
    "class ErrorModel:\n",
    "    def __init__(self, character, correction, occurence):\n",
    "        self.character  = character\n",
    "        self.correction = correction\n",
    "        self.occurence = occurence\n",
    "\n",
    "# Loading error model text file into dictionary\n",
    "error_model = {}\n",
    "file1 = open('count_1edit.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "for line in Lines:\n",
    "    key = line.split('\\t')[0]\n",
    "    value = int(line.split('\\t')[1])\n",
    "    error_model[key] = value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8YCZLi-N0uR"
   },
   "source": [
    "# **Noisy Channel Model Implementation**\n",
    "\n",
    "*Again, you don't have to follow this directly, but consider placing your implementation of the model in the code block below. And while we discussed the general approach in class, kindly describe how you decided to implement the spell correction model. Include any modifications your group made as well. This might be a good spot to place part of your write up.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "VqKjpUrkOSnC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]\n",
      "(0, 0)\n",
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n",
      "(4, 4)\n",
      "transposition\n",
      "no model\n",
      "acres\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 5)]\n",
      "(0, 0)\n",
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n",
      "(4, 4)\n",
      "(5, 5)\n",
      "(6, 5)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-a5e7074c19de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0ms1_idx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0ms2_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0merror_letter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms1_idx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                     \u001b[0mcorrect_letter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms2_idx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms2_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# word = input(\"Input: \")\n",
    "word = \"acress\"\n",
    "\n",
    "one_edit_list = []\n",
    "\n",
    "if word not in all_words:\n",
    "    # Look for words with one edit distance in language model\n",
    "    for key in all_words:\n",
    "        edit_distance = nltk.edit_distance(word, key, substitution_cost=1, transpositions=True)\n",
    "        if edit_distance == 1:\n",
    "            one_edit_list.append(key)\n",
    "            \n",
    "    for candidate in one_edit_list:\n",
    "        flag = False\n",
    "        p_word = all_words[candidate] / total_words\n",
    "        print(candidate)\n",
    "        #print(p_word, end=\" \")\n",
    "        backtrace = nltk.edit_distance_align(word, candidate, substitution_cost=1)\n",
    "        print(backtrace)\n",
    "        \n",
    "        s1 = word\n",
    "        s2 = candidate\n",
    "        for i in range(len(backtrace)):\n",
    "            correct_letter = ''\n",
    "            error_letter = ''\n",
    "            pair = backtrace[i]\n",
    "            s1_idx = pair[0]\n",
    "            s2_idx = pair[1]\n",
    "            print(pair)\n",
    "            \n",
    "            if s1_idx != s2_idx:\n",
    "                # check for insertion\n",
    "                if s1_idx-1 == s2_idx:\n",
    "                    error_letter = s1[s1_idx-1]\n",
    "                    correct_letter = s2[s2_idx-1] + s2[s2_idx]\n",
    "                    flag = True\n",
    "\n",
    "                # check for deletion\n",
    "                elif s1_idx == s2_idx-1:\n",
    "                    error_letter = s1[s1_idx]\n",
    "                    correct_letter = ' '\n",
    "                    flag = True\n",
    "                \n",
    "            elif s1[s1_idx] != s2[s2_idx]:\n",
    "                # check for transposition\n",
    "                if s1[s1_idx+1] == s2[s2_idx] and s1[s1_idx] == s2[s2_idx+1]:\n",
    "                    print('transposition')\n",
    "                    error_letter = s1[s1_idx] + s1[s1_idx+1]\n",
    "                    correct_letter = s2[s2_idx] + s2[s2_idx+1]\n",
    "                    flag = True\n",
    "\n",
    "                # check for substitution\n",
    "                elif s1[s1_idx+1] == s2[s2_idx+1] and s1[s1_idx] != s2[s2_idx]:\n",
    "                    print('substitution')\n",
    "                    error_letter = s1[s1_idx]\n",
    "                    correct_letter = s2[s2_idx]\n",
    "                    flag = True\n",
    "                \n",
    "            error = error_letter + \"|\" + correct_letter\n",
    "            \n",
    "                \n",
    "            if flag:\n",
    "                break\n",
    "        \n",
    "        if error in error_model:\n",
    "            print(error_model[error])\n",
    "        else:\n",
    "            print('no model')\n",
    "\n",
    "else:\n",
    "    print(\"Output: No error\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3smvUR6OXUa"
   },
   "source": [
    "# **Your Relfection / Takeaway / Analysis**\n",
    "\n",
    "*Kindly place the rest of your write up. More information is found in the Canvas write up.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PA4_Spell_Correction_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
